{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load the dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run this notebook, you will need to install: pandas, openai, transformers, plotly, matplotlib, scikit-learn, torch (transformer dep), torchvision, and scipy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.12\n",
      "pip 21.2.4 from C:\\Users\\larsk\\miniconda3\\lib\\site-packages\\pip (python 3.9)\n",
      "\n",
      "Requirement already satisfied: openai in c:\\users\\larsk\\miniconda3\\lib\\site-packages (0.27.4)\n",
      "Requirement already satisfied: tqdm in c:\\users\\larsk\\miniconda3\\lib\\site-packages (from openai) (4.63.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\larsk\\miniconda3\\lib\\site-packages (from openai) (3.8.3)\n",
      "Requirement already satisfied: requests>=2.20 in c:\\users\\larsk\\miniconda3\\lib\\site-packages (from openai) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\larsk\\miniconda3\\lib\\site-packages (from requests>=2.20->openai) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\larsk\\miniconda3\\lib\\site-packages (from requests>=2.20->openai) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\larsk\\miniconda3\\lib\\site-packages (from requests>=2.20->openai) (2023.5.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\larsk\\miniconda3\\lib\\site-packages (from requests>=2.20->openai) (2.0.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\larsk\\miniconda3\\lib\\site-packages (from aiohttp->openai) (6.0.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\larsk\\miniconda3\\lib\\site-packages (from aiohttp->openai) (22.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\larsk\\miniconda3\\lib\\site-packages (from aiohttp->openai) (1.3.3)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\larsk\\miniconda3\\lib\\site-packages (from aiohttp->openai) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\larsk\\miniconda3\\lib\\site-packages (from aiohttp->openai) (1.8.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\larsk\\miniconda3\\lib\\site-packages (from aiohttp->openai) (1.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\larsk\\miniconda3\\lib\\site-packages (from tqdm->openai) (0.4.4)\n"
     ]
    }
   ],
   "source": [
    "#install openai (do this only once at the start. Source: https://community.openai.com/t/no-module-named-openai/8303/3)\n",
    "!python --version\n",
    "!pip --version\n",
    "!pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Import various library's"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import openai\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create embeddings, make sure you change the API key. Currently limits to 200 rows because of token prices."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-05T10:06:12.029064600Z",
     "start_time": "2023-06-05T10:06:09.230434800Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\larsk\\AppData\\Local\\Temp\\ipykernel_16372\\2179164496.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['Embedding'] = data['Clean consumer complaint'].apply(lambda x: get_embedding(x))\n"
     ]
    }
   ],
   "source": [
    "# Setup openAI and constants\n",
    "openai.api_key = \"\"\n",
    "\n",
    "# OpenAI model for embedding complaints: text-embedding-ada-002. link: https://platform.openai.com/docs/models/embeddings\n",
    "embedding_model = \"text-embedding-ada-002\"\n",
    "\n",
    "# Retrieve the data from the database\n",
    "input_datapath = pd.read_csv('StaterData.csv')\n",
    "\n",
    "# Limit test size due to performance issues\n",
    "data = input_datapath.loc[:20]\n",
    "\n",
    "# Create and return embedding\n",
    "def get_embedding(text, model=\"text-embedding-ada-002\"):\n",
    "    # sleep 1 second to prevent reaching rate limit. Limit: 60 requests per min.\n",
    "    time.sleep(1)\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    return openai.Embedding.create(input = [text], model=model)['data'][0]['embedding']\n",
    "\n",
    "data['Embedding'] = data['Clean consumer complaint'].apply(lambda x: get_embedding(x))\n",
    "data.to_csv(\"StaterDataEmbeddings.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Print head of data to check if the data is correct"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21 entries, 0 to 20\n",
      "Data columns (total 5 columns):\n",
      " #   Column                        Non-Null Count  Dtype \n",
      "---  ------                        --------------  ----- \n",
      " 0   Complaint ID                  21 non-null     int64 \n",
      " 1   Issue                         21 non-null     object\n",
      " 2   Consumer complaint narrative  21 non-null     object\n",
      " 3   Clean consumer complaint      21 non-null     object\n",
      " 4   Embedding                     21 non-null     object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 968.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "data.head()\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Used random forest to calculate the accuracy of the embeddings using OpenAI"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-05T10:05:08.671674600Z",
     "start_time": "2023-06-05T10:05:08.452625600Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "the JSON object must be str, bytes or bytearray, not list",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[10], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Prepare the feature matrix X and target vector y\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m X \u001B[38;5;241m=\u001B[39m \u001B[43mdata\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mEmbedding\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43;01mlambda\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mjson\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mloads\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mtolist()\n\u001B[0;32m      3\u001B[0m y \u001B[38;5;241m=\u001B[39m data[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIssue\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m      5\u001B[0m \u001B[38;5;66;03m# Reshape the embeddings into a 2D array\u001B[39;00m\n",
      "File \u001B[1;32m~\\miniconda3\\lib\\site-packages\\pandas\\core\\series.py:4626\u001B[0m, in \u001B[0;36mSeries.apply\u001B[1;34m(self, func, convert_dtype, args, **kwargs)\u001B[0m\n\u001B[0;32m   4516\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mapply\u001B[39m(\n\u001B[0;32m   4517\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   4518\u001B[0m     func: AggFuncType,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   4521\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m   4522\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m DataFrame \u001B[38;5;241m|\u001B[39m Series:\n\u001B[0;32m   4523\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   4524\u001B[0m \u001B[38;5;124;03m    Invoke function on values of Series.\u001B[39;00m\n\u001B[0;32m   4525\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   4624\u001B[0m \u001B[38;5;124;03m    dtype: float64\u001B[39;00m\n\u001B[0;32m   4625\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 4626\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mSeriesApply\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconvert_dtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\lib\\site-packages\\pandas\\core\\apply.py:1025\u001B[0m, in \u001B[0;36mSeriesApply.apply\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1022\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapply_str()\n\u001B[0;32m   1024\u001B[0m \u001B[38;5;66;03m# self.f is Callable\u001B[39;00m\n\u001B[1;32m-> 1025\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply_standard\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\lib\\site-packages\\pandas\\core\\apply.py:1076\u001B[0m, in \u001B[0;36mSeriesApply.apply_standard\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1074\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1075\u001B[0m         values \u001B[38;5;241m=\u001B[39m obj\u001B[38;5;241m.\u001B[39mastype(\u001B[38;5;28mobject\u001B[39m)\u001B[38;5;241m.\u001B[39m_values\n\u001B[1;32m-> 1076\u001B[0m         mapped \u001B[38;5;241m=\u001B[39m \u001B[43mlib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap_infer\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1077\u001B[0m \u001B[43m            \u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1078\u001B[0m \u001B[43m            \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1079\u001B[0m \u001B[43m            \u001B[49m\u001B[43mconvert\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconvert_dtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1080\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1082\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(mapped) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(mapped[\u001B[38;5;241m0\u001B[39m], ABCSeries):\n\u001B[0;32m   1083\u001B[0m     \u001B[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001B[39;00m\n\u001B[0;32m   1084\u001B[0m     \u001B[38;5;66;03m#  See also GH#25959 regarding EA support\u001B[39;00m\n\u001B[0;32m   1085\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m obj\u001B[38;5;241m.\u001B[39m_constructor_expanddim(\u001B[38;5;28mlist\u001B[39m(mapped), index\u001B[38;5;241m=\u001B[39mobj\u001B[38;5;241m.\u001B[39mindex)\n",
      "File \u001B[1;32m~\\miniconda3\\lib\\site-packages\\pandas\\_libs\\lib.pyx:2834\u001B[0m, in \u001B[0;36mpandas._libs.lib.map_infer\u001B[1;34m()\u001B[0m\n",
      "Cell \u001B[1;32mIn[10], line 2\u001B[0m, in \u001B[0;36m<lambda>\u001B[1;34m(x)\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Prepare the feature matrix X and target vector y\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m X \u001B[38;5;241m=\u001B[39m data[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEmbedding\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mapply(\u001B[38;5;28;01mlambda\u001B[39;00m x: \u001B[43mjson\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mloads\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m)\u001B[38;5;241m.\u001B[39mtolist()\n\u001B[0;32m      3\u001B[0m y \u001B[38;5;241m=\u001B[39m data[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIssue\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m      5\u001B[0m \u001B[38;5;66;03m# Reshape the embeddings into a 2D array\u001B[39;00m\n",
      "File \u001B[1;32m~\\miniconda3\\lib\\json\\__init__.py:339\u001B[0m, in \u001B[0;36mloads\u001B[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001B[0m\n\u001B[0;32m    337\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    338\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(s, (\u001B[38;5;28mbytes\u001B[39m, \u001B[38;5;28mbytearray\u001B[39m)):\n\u001B[1;32m--> 339\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mthe JSON object must be str, bytes or bytearray, \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m    340\u001B[0m                         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnot \u001B[39m\u001B[38;5;132;01m{\u001B[39;00ms\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m    341\u001B[0m     s \u001B[38;5;241m=\u001B[39m s\u001B[38;5;241m.\u001B[39mdecode(detect_encoding(s), \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msurrogatepass\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m    343\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\u001B[38;5;28mcls\u001B[39m \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m object_hook \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m\n\u001B[0;32m    344\u001B[0m         parse_int \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m parse_float \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m\n\u001B[0;32m    345\u001B[0m         parse_constant \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m object_pairs_hook \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m kw):\n",
      "\u001B[1;31mTypeError\u001B[0m: the JSON object must be str, bytes or bytearray, not list"
     ]
    }
   ],
   "source": [
    "# Prepare the feature matrix X and target vector y\n",
    "X = data[\"Embedding\"].apply(lambda x: json.loads(x)).tolist()\n",
    "y = data[\"Issue\"]\n",
    "\n",
    "# Reshape the embeddings into a 2D array\n",
    "X = np.array(X)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=2)\n",
    "\n",
    "# Create an instance of the random forest classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=200, random_state=2)\n",
    "\n",
    "# Train the random forest classifier\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy for this model is 0.54. It is an ok model as the complaints are not cleaned yet."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "365536dcbde60510dc9073d6b991cd35db2d9bac356a11f5b64279a5e6708b97"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
