{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MakerSuite embeddings, using embeddings to convert the text to vectorized and on that classify it using SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as palm\n",
    "\n",
    "import re\n",
    "import tqdm\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import pandas as pd\n",
    "\n",
    "from keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from google.api_core import retry\n",
    "from tqdm.auto import tqdm\n",
    "import sys\n",
    "import platform"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making sure that the kernals are correctly in use and that all resources are available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Platform: macOS-13.4-arm64-arm-64bit\n",
      "Tensor Flow Version: 2.12.0\n",
      "Keras Version: 2.12.0\n",
      "\n",
      "Python 3.10.11 | packaged by conda-forge | (main, May 10 2023, 19:01:19) [Clang 14.0.6 ]\n",
      "Pandas 2.0.1\n",
      "Scikit-Learn 1.2.2\n",
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "print(f\"Python Platform: {platform.platform()}\")\n",
    "print(f\"Tensor Flow Version: {tf.__version__}\")\n",
    "print(f\"Keras Version: {tf.keras.__version__}\")\n",
    "print()\n",
    "print(f\"Python {sys.version}\")\n",
    "print(f\"Pandas {pd.__version__}\")\n",
    "print(f\"Scikit-Learn {sk.__version__}\")\n",
    "gpu = len(tf.config.list_physical_devices('GPU'))>0\n",
    "print(\"GPU is\", \"available\" if gpu else \"NOT AVAILABLE\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting the api key and the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "palm.configure(api_key='AIzaSyDl-GxBo7WsAQiw99q5yKACHkQ7c-ysIQ8')\n",
    "models = [m for m in palm.list_models() if 'embedText' in m.supported_generation_methods]\n",
    "\n",
    "model = models[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing the data and create a train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data, and spit the data\n",
    "data = pd.read_csv(\"StaterData.csv\")\n",
    "\n",
    "issue_to_int = {\n",
    "    \"Trouble during payment process\": 0,\n",
    "    \"Struggling to pay mortgage\": 1,\n",
    "    \"Loan servicing, payments, escrow account\": 2,\n",
    "    \"Applying for a mortgage or refinancing an existing mortgage\": 3,\n",
    "    \"Loan modification,collection,foreclosure\": 4,\n",
    "    \"Closing on a mortgage\": 5,\n",
    "    \"Application, originator, mortgage broker\": 6,\n",
    "    \"Credit decision / Underwriting\": 7,\n",
    "    \"Incorrect information on your report\": 8,\n",
    "    \"Settlement process and costs\": 9,\n",
    "    \"Problem with a credit reporting company's investigation into an existing problem\": 10,\n",
    "    \"Improper use of your report\": 11,\n",
    "    \"Credit monitoring or identity theft protection services\": 12,\n",
    "}\n",
    "\n",
    "# Create a new column called `Issue_Int`\n",
    "data[\"Issue_Int\"] = data[\"Issue\"].map(issue_to_int)\n",
    "\n",
    "data = data[data['Issue'] == 'Trouble during payment process'].sample(n=18000, random_state=2)\n",
    "\n",
    "df_train, df_test = train_test_split(data, test_size=0.3, random_state=2)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling the API from Palm and convert the text to vectors, PaLM api limit is currently 4 items per second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2acc93336b4346f2aa70a5fa2e4557ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[39mreturn\u001b[39;00m data\n\u001b[1;32m     17\u001b[0m \u001b[39m# Creates the embedding for the train and the testdata\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m df_train \u001b[39m=\u001b[39m create_embeddings(model, df_train)\n\u001b[1;32m     19\u001b[0m df_test \u001b[39m=\u001b[39m create_embeddings(model, df_test)\n",
      "Cell \u001b[0;32mIn[17], line 14\u001b[0m, in \u001b[0;36mcreate_embeddings\u001b[0;34m(model, data)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate_embeddings\u001b[39m(model, data):\n\u001b[1;32m     13\u001b[0m   \u001b[39m# Adds the column embeddings with the corrosponding embedding\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m   data[\u001b[39m'\u001b[39m\u001b[39mEmbeddings\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m data[\u001b[39m'\u001b[39;49m\u001b[39mConsumer complaint narrative\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mprogress_apply(make_embed_text_fn(model))\n\u001b[1;32m     15\u001b[0m   \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.10/site-packages/tqdm/std.py:805\u001b[0m, in \u001b[0;36mtqdm.pandas.<locals>.inner_generator.<locals>.inner\u001b[0;34m(df, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    802\u001b[0m \u001b[39m# Apply the provided function (in **kwargs)\u001b[39;00m\n\u001b[1;32m    803\u001b[0m \u001b[39m# on the df using our wrapper (which provides bar updating)\u001b[39;00m\n\u001b[1;32m    804\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 805\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39;49m(df, df_function)(wrapper, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    806\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    807\u001b[0m     t\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.10/site-packages/pandas/core/series.py:4626\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4516\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[1;32m   4517\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   4518\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4521\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   4522\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[1;32m   4523\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   4524\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4525\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4624\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4625\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4626\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39;49m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.10/site-packages/pandas/core/apply.py:1025\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[1;32m   1024\u001b[0m \u001b[39m# self.f is Callable\u001b[39;00m\n\u001b[0;32m-> 1025\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.10/site-packages/pandas/core/apply.py:1076\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1074\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1075\u001b[0m         values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[0;32m-> 1076\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer(\n\u001b[1;32m   1077\u001b[0m             values,\n\u001b[1;32m   1078\u001b[0m             f,\n\u001b[1;32m   1079\u001b[0m             convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype,\n\u001b[1;32m   1080\u001b[0m         )\n\u001b[1;32m   1082\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1083\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1085\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.10/site-packages/pandas/_libs/lib.pyx:2834\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.10/site-packages/tqdm/std.py:800\u001b[0m, in \u001b[0;36mtqdm.pandas.<locals>.inner_generator.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    794\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    795\u001b[0m     \u001b[39m# update tbar correctly\u001b[39;00m\n\u001b[1;32m    796\u001b[0m     \u001b[39m# it seems `pandas apply` calls `func` twice\u001b[39;00m\n\u001b[1;32m    797\u001b[0m     \u001b[39m# on the first column/row to decide whether it can\u001b[39;00m\n\u001b[1;32m    798\u001b[0m     \u001b[39m# take a fast or slow code path; so stop when t.total==t.n\u001b[39;00m\n\u001b[1;32m    799\u001b[0m     t\u001b[39m.\u001b[39mupdate(n\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m t\u001b[39m.\u001b[39mtotal \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mn \u001b[39m<\u001b[39m t\u001b[39m.\u001b[39mtotal \u001b[39melse\u001b[39;00m \u001b[39m0\u001b[39m)\n\u001b[0;32m--> 800\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.10/site-packages/google/api_core/retry.py:349\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    345\u001b[0m target \u001b[39m=\u001b[39m functools\u001b[39m.\u001b[39mpartial(func, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    346\u001b[0m sleep_generator \u001b[39m=\u001b[39m exponential_sleep_generator(\n\u001b[1;32m    347\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_initial, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maximum, multiplier\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_multiplier\n\u001b[1;32m    348\u001b[0m )\n\u001b[0;32m--> 349\u001b[0m \u001b[39mreturn\u001b[39;00m retry_target(\n\u001b[1;32m    350\u001b[0m     target,\n\u001b[1;32m    351\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_predicate,\n\u001b[1;32m    352\u001b[0m     sleep_generator,\n\u001b[1;32m    353\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_timeout,\n\u001b[1;32m    354\u001b[0m     on_error\u001b[39m=\u001b[39;49mon_error,\n\u001b[1;32m    355\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.10/site-packages/google/api_core/retry.py:191\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, **kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[39mfor\u001b[39;00m sleep \u001b[39min\u001b[39;00m sleep_generator:\n\u001b[1;32m    190\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 191\u001b[0m         \u001b[39mreturn\u001b[39;00m target()\n\u001b[1;32m    193\u001b[0m     \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m    194\u001b[0m     \u001b[39m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[1;32m    195\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n",
      "Cell \u001b[0;32mIn[17], line 8\u001b[0m, in \u001b[0;36mmake_embed_text_fn.<locals>.embed_fn\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[39m@retry\u001b[39m\u001b[39m.\u001b[39mRetry(timeout\u001b[39m=\u001b[39m\u001b[39m300.0\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39membed_fn\u001b[39m(text: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mlist\u001b[39m[\u001b[39mfloat\u001b[39m]:\n\u001b[1;32m      7\u001b[0m   \u001b[39m# Using the palm model generate the embeddings for \u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m   \u001b[39mreturn\u001b[39;00m palm\u001b[39m.\u001b[39;49mgenerate_embeddings(model\u001b[39m=\u001b[39;49mmodel, text\u001b[39m=\u001b[39;49mtext)[\u001b[39m'\u001b[39m\u001b[39membedding\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.10/site-packages/google/generativeai/text.py:196\u001b[0m, in \u001b[0;36mgenerate_embeddings\u001b[0;34m(model, text, client)\u001b[0m\n\u001b[1;32m    193\u001b[0m     client \u001b[39m=\u001b[39m get_default_text_client()\n\u001b[1;32m    195\u001b[0m embedding_request \u001b[39m=\u001b[39m glm\u001b[39m.\u001b[39mEmbedTextRequest(model\u001b[39m=\u001b[39mmodel, text\u001b[39m=\u001b[39mtext)\n\u001b[0;32m--> 196\u001b[0m embedding_response \u001b[39m=\u001b[39m client\u001b[39m.\u001b[39;49membed_text(embedding_request)\n\u001b[1;32m    198\u001b[0m embedding_dict \u001b[39m=\u001b[39m \u001b[39mtype\u001b[39m(embedding_response)\u001b[39m.\u001b[39mto_dict(embedding_response)\n\u001b[1;32m    200\u001b[0m embedding_dict[\u001b[39m\"\u001b[39m\u001b[39membedding\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m embedding_dict[\u001b[39m\"\u001b[39m\u001b[39membedding\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.10/site-packages/google/ai/generativelanguage_v1beta2/services/text_service/client.py:754\u001b[0m, in \u001b[0;36mTextServiceClient.embed_text\u001b[0;34m(self, request, model, text, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    749\u001b[0m metadata \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(metadata) \u001b[39m+\u001b[39m (\n\u001b[1;32m    750\u001b[0m     gapic_v1\u001b[39m.\u001b[39mrouting_header\u001b[39m.\u001b[39mto_grpc_metadata(((\u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m, request\u001b[39m.\u001b[39mmodel),)),\n\u001b[1;32m    751\u001b[0m )\n\u001b[1;32m    753\u001b[0m \u001b[39m# Send the request.\u001b[39;00m\n\u001b[0;32m--> 754\u001b[0m response \u001b[39m=\u001b[39m rpc(\n\u001b[1;32m    755\u001b[0m     request,\n\u001b[1;32m    756\u001b[0m     retry\u001b[39m=\u001b[39;49mretry,\n\u001b[1;32m    757\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    758\u001b[0m     metadata\u001b[39m=\u001b[39;49mmetadata,\n\u001b[1;32m    759\u001b[0m )\n\u001b[1;32m    761\u001b[0m \u001b[39m# Done; return the response.\u001b[39;00m\n\u001b[1;32m    762\u001b[0m \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.10/site-packages/google/api_core/gapic_v1/method.py:113\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[0;34m(self, timeout, retry, *args, **kwargs)\u001b[0m\n\u001b[1;32m    110\u001b[0m     metadata\u001b[39m.\u001b[39mextend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_metadata)\n\u001b[1;32m    111\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39mmetadata\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m metadata\n\u001b[0;32m--> 113\u001b[0m \u001b[39mreturn\u001b[39;00m wrapped_func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.10/site-packages/google/api_core/grpc_helpers.py:72\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(callable_)\n\u001b[1;32m     70\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39merror_remapped_callable\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     71\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 72\u001b[0m         \u001b[39mreturn\u001b[39;00m callable_(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     73\u001b[0m     \u001b[39mexcept\u001b[39;00m grpc\u001b[39m.\u001b[39mRpcError \u001b[39mas\u001b[39;00m exc:\n\u001b[1;32m     74\u001b[0m         \u001b[39mraise\u001b[39;00m exceptions\u001b[39m.\u001b[39mfrom_grpc_error(exc) \u001b[39mfrom\u001b[39;00m \u001b[39mexc\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.10/site-packages/grpc/_channel.py:1028\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1021\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m,\n\u001b[1;32m   1022\u001b[0m              request: Any,\n\u001b[1;32m   1023\u001b[0m              timeout: Optional[\u001b[39mfloat\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1026\u001b[0m              wait_for_ready: Optional[\u001b[39mbool\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1027\u001b[0m              compression: Optional[grpc\u001b[39m.\u001b[39mCompression] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m-> 1028\u001b[0m     state, call, \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_blocking(request, timeout, metadata, credentials,\n\u001b[1;32m   1029\u001b[0m                                   wait_for_ready, compression)\n\u001b[1;32m   1030\u001b[0m     \u001b[39mreturn\u001b[39;00m _end_unary_response_blocking(state, call, \u001b[39mFalse\u001b[39;00m, \u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.10/site-packages/grpc/_channel.py:1017\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable._blocking\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1009\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1010\u001b[0m     call \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_channel\u001b[39m.\u001b[39msegregated_call(\n\u001b[1;32m   1011\u001b[0m         cygrpc\u001b[39m.\u001b[39mPropagationConstants\u001b[39m.\u001b[39mGRPC_PROPAGATE_DEFAULTS,\n\u001b[1;32m   1012\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_method, \u001b[39mNone\u001b[39;00m, _determine_deadline(deadline), metadata,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1015\u001b[0m             \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1016\u001b[0m         ),), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_context)\n\u001b[0;32m-> 1017\u001b[0m     event \u001b[39m=\u001b[39m call\u001b[39m.\u001b[39;49mnext_event()\n\u001b[1;32m   1018\u001b[0m     _handle_event(event, state, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_response_deserializer)\n\u001b[1;32m   1019\u001b[0m     \u001b[39mreturn\u001b[39;00m state, call\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi:338\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc.SegregatedCall.next_event\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi:169\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._next_call_event\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi:163\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._next_call_event\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi:78\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._latent_event\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi:61\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._internal_latent_event\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi:42\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._next\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Python progress bar \n",
    "tqdm.pandas()\n",
    "\n",
    "def make_embed_text_fn(model):\n",
    "  @retry.Retry(timeout=300.0)\n",
    "  def embed_fn(text: str) -> list[float]:\n",
    "    # Using the palm model generate the embeddings for \n",
    "    return palm.generate_embeddings(model=model, text=text)['embedding']\n",
    "  return embed_fn\n",
    "\n",
    "# Creates the embedding of the send dataframe\n",
    "def create_embeddings(model, data):\n",
    "  # Adds the column embeddings with the corrosponding embedding\n",
    "  data['Embeddings'] = data['Consumer complaint narrative'].progress_apply(make_embed_text_fn(model))\n",
    "  return data\n",
    "\n",
    "# Creates the embedding for the train and the testdata\n",
    "df_train = create_embeddings(model, df_train)\n",
    "df_test = create_embeddings(model, df_test)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the Keras model, used for the classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classification_model(input_size: int, num_classes: int) -> keras.Model:\n",
    "  inputs = x = keras.Input(input_size)\n",
    "  x = layers.Dense(input_size, activation='relu')(x)\n",
    "  x = layers.Dense(num_classes, activation='sigmoid')(x)\n",
    "  return keras.Model(inputs=[inputs], outputs=x)\n",
    "\n",
    "# Derive the embedding size from the first training element.\n",
    "embedding_size = len(df_train['Embeddings'].iloc[0])\n",
    "\n",
    "# Give your model a different name, as you have already used the variable name 'model'\n",
    "classifier = build_classification_model(embedding_size, len(df_train['Consumer complaint narrative'].unique()))\n",
    "classifier.summary()\n",
    "\n",
    "classifier.compile(loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                   optimizer = keras.optimizers.Adam(learning_rate=0.001),\n",
    "                   metrics=['accuracy'])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 20\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "# Split the x and y components of the train and validation subsets.\n",
    "y_train = df_train['Issue_Int']\n",
    "x_train = np.stack(df_train['Embeddings'])\n",
    "y_val = df_test['Issue_Int']\n",
    "x_val = np.stack(df_test['Embeddings'])\n",
    "\n",
    "# Train the model for the desired number of epochs.\n",
    "callback = keras.callbacks.EarlyStopping(monitor='accuracy', patience=3)\n",
    "\n",
    "history = classifier.fit(x=x_train,\n",
    "                         y=y_train,\n",
    "                         validation_data=(x_val, y_val),\n",
    "                         callbacks=[callback],\n",
    "                         batch_size=BATCH_SIZE,\n",
    "                         epochs=NUM_EPOCHS,) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate how accurate the model is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.evaluate(x=x_val, y=y_val, return_dict=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create 2 plots that show the accuracy over the amounts of epochs and loses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "  fig, (ax1, ax2) = plt.subplots(1,2)\n",
    "  fig.set_size_inches(20, 8)\n",
    "\n",
    "  # Plot loss\n",
    "  ax1.set_title('Loss')\n",
    "  ax1.plot(history.history['loss'], label = 'train')\n",
    "  ax1.plot(history.history['val_loss'], label = 'test')\n",
    "  ax1.set_ylabel('Loss')\n",
    "\n",
    "  ax1.set_xlabel('Epoch')\n",
    "  ax1.legend(['Train', 'Validation'])\n",
    "\n",
    "  # Plot accuracy\n",
    "  ax2.set_title('Accuracy')\n",
    "  ax2.plot(history.history['accuracy'],  label = 'train')\n",
    "  ax2.plot(history.history['val_accuracy'], label = 'test')\n",
    "  ax2.set_ylabel('Accuracy')\n",
    "  ax2.set_xlabel('Epoch')\n",
    "  ax2.legend(['Train', 'Validation'])\n",
    "\n",
    "  plt.show()\n",
    "\n",
    "plot_history(history)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model shows great promise, without cleaning the text the model almost gives the same accuracy as using TF-IDF with cleaning"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
