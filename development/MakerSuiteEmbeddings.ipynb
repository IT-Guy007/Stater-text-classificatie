{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as palm\n",
    "\n",
    "import re\n",
    "import tqdm\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras import layers\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import sklearn.metrics as skmetrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from google.api_core import retry\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import sys\n",
    "import platform\n",
    "\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Platform: macOS-13.3.1-arm64-arm-64bit\n",
      "Tensor Flow Version: 2.12.0\n",
      "Keras Version: 2.12.0\n",
      "\n",
      "Python 3.10.11 | packaged by conda-forge | (main, May 10 2023, 19:01:19) [Clang 14.0.6 ]\n",
      "Pandas 2.0.1\n",
      "Scikit-Learn 1.2.2\n",
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "print(f\"Python Platform: {platform.platform()}\")\n",
    "print(f\"Tensor Flow Version: {tf.__version__}\")\n",
    "print(f\"Keras Version: {tf.keras.__version__}\")\n",
    "print()\n",
    "print(f\"Python {sys.version}\")\n",
    "print(f\"Pandas {pd.__version__}\")\n",
    "print(f\"Scikit-Learn {sk.__version__}\")\n",
    "gpu = len(tf.config.list_physical_devices('GPU'))>0\n",
    "print(\"GPU is\", \"available\" if gpu else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ServiceUnavailable",
     "evalue": "503 DNS resolution failed for generativelanguage.googleapis.com:443: C-ares status is not ARES_SUCCESS qtype=A name=generativelanguage.googleapis.com is_balancer=0: Timeout while contacting DNS servers",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_InactiveRpcError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.10/site-packages/google/api_core/grpc_helpers.py:72\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 72\u001b[0m     \u001b[39mreturn\u001b[39;00m callable_(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     73\u001b[0m \u001b[39mexcept\u001b[39;00m grpc\u001b[39m.\u001b[39mRpcError \u001b[39mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.10/site-packages/grpc/_channel.py:1030\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1028\u001b[0m state, call, \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_blocking(request, timeout, metadata, credentials,\n\u001b[1;32m   1029\u001b[0m                               wait_for_ready, compression)\n\u001b[0;32m-> 1030\u001b[0m \u001b[39mreturn\u001b[39;00m _end_unary_response_blocking(state, call, \u001b[39mFalse\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.10/site-packages/grpc/_channel.py:910\u001b[0m, in \u001b[0;36m_end_unary_response_blocking\u001b[0;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[1;32m    909\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 910\u001b[0m     \u001b[39mraise\u001b[39;00m _InactiveRpcError(state)\n",
      "\u001b[0;31m_InactiveRpcError\u001b[0m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.UNAVAILABLE\n\tdetails = \"DNS resolution failed for generativelanguage.googleapis.com:443: C-ares status is not ARES_SUCCESS qtype=A name=generativelanguage.googleapis.com is_balancer=0: Timeout while contacting DNS servers\"\n\tdebug_error_string = \"UNKNOWN:DNS resolution failed for generativelanguage.googleapis.com:443: C-ares status is not ARES_SUCCESS qtype=A name=generativelanguage.googleapis.com is_balancer=0: Timeout while contacting DNS servers {created_time:\"2023-05-25T12:06:20.710344+02:00\", grpc_status:14}\"\n>",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mServiceUnavailable\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m palm\u001b[39m.\u001b[39mconfigure(api_key\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mAIzaSyBR_y_hrnO_l3S5SZG5Pd2X6tE0GdnbXBk\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m models \u001b[39m=\u001b[39m [m \u001b[39mfor\u001b[39;00m m \u001b[39min\u001b[39;00m palm\u001b[39m.\u001b[39;49mlist_models() \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39membedText\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m m\u001b[39m.\u001b[39msupported_generation_methods]\n\u001b[1;32m      4\u001b[0m model \u001b[39m=\u001b[39m models[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.10/site-packages/google/generativeai/models.py:95\u001b[0m, in \u001b[0;36mlist_models\u001b[0;34m(page_size, client)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[39mif\u001b[39;00m client \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     93\u001b[0m     client \u001b[39m=\u001b[39m get_default_model_client()\n\u001b[0;32m---> 95\u001b[0m \u001b[39mreturn\u001b[39;00m _list_models(page_size, page_token\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, client\u001b[39m=\u001b[39;49mclient)\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.10/site-packages/google/generativeai/models.py:62\u001b[0m, in \u001b[0;36m_list_models\u001b[0;34m(page_size, page_token, client)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_list_models\u001b[39m(page_size, page_token, client):\n\u001b[0;32m---> 62\u001b[0m     result \u001b[39m=\u001b[39m client\u001b[39m.\u001b[39;49mlist_models(page_size\u001b[39m=\u001b[39;49mpage_size, page_token\u001b[39m=\u001b[39;49mpage_token)\n\u001b[1;32m     63\u001b[0m     result \u001b[39m=\u001b[39m result\u001b[39m.\u001b[39m_response\n\u001b[1;32m     64\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mtype\u001b[39m(result)\u001b[39m.\u001b[39mto_dict(result)\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.10/site-packages/google/ai/generativelanguage_v1beta2/services/model_service/client.py:654\u001b[0m, in \u001b[0;36mModelServiceClient.list_models\u001b[0;34m(self, request, page_size, page_token, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    651\u001b[0m rpc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_transport\u001b[39m.\u001b[39m_wrapped_methods[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_transport\u001b[39m.\u001b[39mlist_models]\n\u001b[1;32m    653\u001b[0m \u001b[39m# Send the request.\u001b[39;00m\n\u001b[0;32m--> 654\u001b[0m response \u001b[39m=\u001b[39m rpc(\n\u001b[1;32m    655\u001b[0m     request,\n\u001b[1;32m    656\u001b[0m     retry\u001b[39m=\u001b[39;49mretry,\n\u001b[1;32m    657\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    658\u001b[0m     metadata\u001b[39m=\u001b[39;49mmetadata,\n\u001b[1;32m    659\u001b[0m )\n\u001b[1;32m    661\u001b[0m \u001b[39m# This method is paged; wrap the response in a pager, which provides\u001b[39;00m\n\u001b[1;32m    662\u001b[0m \u001b[39m# an `__iter__` convenience method.\u001b[39;00m\n\u001b[1;32m    663\u001b[0m response \u001b[39m=\u001b[39m pagers\u001b[39m.\u001b[39mListModelsPager(\n\u001b[1;32m    664\u001b[0m     method\u001b[39m=\u001b[39mrpc,\n\u001b[1;32m    665\u001b[0m     request\u001b[39m=\u001b[39mrequest,\n\u001b[1;32m    666\u001b[0m     response\u001b[39m=\u001b[39mresponse,\n\u001b[1;32m    667\u001b[0m     metadata\u001b[39m=\u001b[39mmetadata,\n\u001b[1;32m    668\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.10/site-packages/google/api_core/gapic_v1/method.py:113\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[0;34m(self, timeout, retry, *args, **kwargs)\u001b[0m\n\u001b[1;32m    110\u001b[0m     metadata\u001b[39m.\u001b[39mextend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_metadata)\n\u001b[1;32m    111\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39mmetadata\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m metadata\n\u001b[0;32m--> 113\u001b[0m \u001b[39mreturn\u001b[39;00m wrapped_func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.10/site-packages/google/api_core/grpc_helpers.py:74\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[39mreturn\u001b[39;00m callable_(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m     73\u001b[0m \u001b[39mexcept\u001b[39;00m grpc\u001b[39m.\u001b[39mRpcError \u001b[39mas\u001b[39;00m exc:\n\u001b[0;32m---> 74\u001b[0m     \u001b[39mraise\u001b[39;00m exceptions\u001b[39m.\u001b[39mfrom_grpc_error(exc) \u001b[39mfrom\u001b[39;00m \u001b[39mexc\u001b[39;00m\n",
      "\u001b[0;31mServiceUnavailable\u001b[0m: 503 DNS resolution failed for generativelanguage.googleapis.com:443: C-ares status is not ARES_SUCCESS qtype=A name=generativelanguage.googleapis.com is_balancer=0: Timeout while contacting DNS servers"
     ]
    }
   ],
   "source": [
    "palm.configure(api_key='AIzaSyBR_y_hrnO_l3S5SZG5Pd2X6tE0GdnbXBk')\n",
    "models = [m for m in palm.list_models() if 'embedText' in m.supported_generation_methods]\n",
    "\n",
    "model = models[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data, and spit the data\n",
    "data = pd.read_sql_query(\"SELECT * FROM 'mortgage complaints'\", \"sqlite:///StaterData.db\")\n",
    "\n",
    "data[data['Consumer complaint narrative'].notna()]\n",
    "\n",
    "data['Consumer complaint narrative'] = data['Consumer complaint narrative'].str.lower()\n",
    "data['Consumer complaint narrative'] = data['Consumer complaint narrative'].str.replace('x', '') # Remove \"X\"\n",
    "data['Consumer complaint narrative'] = data['Consumer complaint narrative'].str.replace('/', '') # Remove \"/\"\n",
    "\n",
    "def remove_patterns(text):\n",
    "    # Define the patterns you want to remove\n",
    "    patterns = ['\\d{2}/\\d{2}/\\d{4}', '\\d{4}']\n",
    "    \n",
    "    # Compile the regex patterns\n",
    "    regex_patterns = [re.compile(pattern) for pattern in patterns]\n",
    "    \n",
    "    # Replace the patterns with an empty string\n",
    "    for pattern in regex_patterns:\n",
    "        text = pattern.sub('', text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "data['Consumer complaint narrative'] = data['Consumer complaint narrative'].apply(remove_patterns)\n",
    "\n",
    "issue_to_int = {\n",
    "    \"Trouble during payment process\": 0,\n",
    "    \"Struggling to pay mortgage\": 1,\n",
    "    \"Loan servicing, payments, escrow account\": 2,\n",
    "    \"Applying for a mortgage or refinancing an existing mortgage\": 3,\n",
    "    \"Loan modification,collection,foreclosure\": 4,\n",
    "    \"Closing on a mortgage\": 5,\n",
    "    \"Application, originator, mortgage broker\": 6,\n",
    "    \"Credit decision / Underwriting\": 7,\n",
    "    \"Incorrect information on your report\": 8,\n",
    "    \"Settlement process and costs\": 9,\n",
    "    \"Problem with a credit reporting company's investigation into an existing problem\": 10,\n",
    "    \"Improper use of your report\": 11,\n",
    "    \"Credit monitoring or identity theft protection services\": 12,\n",
    "}\n",
    "\n",
    "# Create a new column called `Issue_Int`\n",
    "data[\"Issue_Int\"] = data[\"Issue\"].map(issue_to_int)\n",
    "\n",
    "\n",
    "df_train, df_test = train_test_split(data, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a python progress ba \n",
    "tqdm.pandas()\n",
    "\n",
    "def make_embed_text_fn(model):\n",
    "  @retry.Retry(timeout=300.0)\n",
    "  def embed_fn(text: str) -> list[float]:\n",
    "    # Using the palm model generate the embeddings for \n",
    "    return palm.generate_embeddings(model=model, text=text)['embedding']\n",
    "  return embed_fn\n",
    "\n",
    "# Creates the embedding of the send dataframe\n",
    "def create_embeddings(model, data):\n",
    "  # Adds the column embeddings with the corrosponding embedding\n",
    "  data['Embeddings'] = data['Consumer complaint narrative'].progress_apply(make_embed_text_fn(model))\n",
    "  return data\n",
    "\n",
    "# Creates the embedding for the train and the testdata\n",
    "df_train = create_embeddings(model, df_train)\n",
    "df_test = create_embeddings(model, df_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(df_train, \"df_train.joblib\")\n",
    "joblib.dump(df_test, \"df_test.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf = SVC(C=10, class_weight='balanced', gamma='scale', kernel='linear')\n",
    "\n",
    "# X_train = df_train['Embeddings'].tolist()\n",
    "# y_train = df_train['Issue']\n",
    "\n",
    "# X_test = df_test['Embeddings'].tolist()\n",
    "# y_test = df_test['Issue']\n",
    "\n",
    "# clf.fit(X_train, y_train)\n",
    "\n",
    "# y_pred = clf.predict(X_test)\n",
    "\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classification_model(input_size: int, num_classes: int) -> keras.Model:\n",
    "  inputs = x = keras.Input(input_size)\n",
    "  x = layers.Dense(input_size, activation='relu')(x)\n",
    "  x = layers.Dense(num_classes, activation='sigmoid')(x)\n",
    "  return keras.Model(inputs=[inputs], outputs=x)\n",
    "\n",
    "# Derive the embedding size from the first training element.\n",
    "embedding_size = len(df_train['Embeddings'].iloc[0])\n",
    "\n",
    "# Give your model a different name, as you have already used the variable name 'model'\n",
    "classifier = build_classification_model(embedding_size, len(df_train['Consumer complaint narrative'].unique()))\n",
    "classifier.summary()\n",
    "\n",
    "classifier.compile(loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                   optimizer = keras.optimizers.Adam(learning_rate=0.001),\n",
    "                   metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = joblib.load(\"df_train.joblib\")\n",
    "df_test = joblib.load(\"df_test.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 20\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "# Split the x and y components of the train and validation subsets.\n",
    "y_train = df_train['Issue_Int']\n",
    "x_train = np.stack(df_train['Embeddings'])\n",
    "y_val = df_test['Issue_Int']\n",
    "x_val = np.stack(df_test['Embeddings'])\n",
    "\n",
    "# Train the model for the desired number of epochs.\n",
    "callback = keras.callbacks.EarlyStopping(monitor='accuracy', patience=3)\n",
    "\n",
    "history = classifier.fit(x=x_train,\n",
    "                         y=y_train,\n",
    "                         validation_data=(x_val, y_val),\n",
    "                         callbacks=[callback],\n",
    "                         batch_size=BATCH_SIZE,\n",
    "                         epochs=NUM_EPOCHS,) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.evaluate(x=x_val, y=y_val, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "  fig, (ax1, ax2) = plt.subplots(1,2)\n",
    "  fig.set_size_inches(20, 8)\n",
    "\n",
    "  # Plot loss\n",
    "  ax1.set_title('Loss')\n",
    "  ax1.plot(history.history['loss'], label = 'train')\n",
    "  ax1.plot(history.history['val_loss'], label = 'test')\n",
    "  ax1.set_ylabel('Loss')\n",
    "\n",
    "  ax1.set_xlabel('Epoch')\n",
    "  ax1.legend(['Train', 'Validation'])\n",
    "\n",
    "  # Plot accuracy\n",
    "  ax2.set_title('Accuracy')\n",
    "  ax2.plot(history.history['accuracy'],  label = 'train')\n",
    "  ax2.plot(history.history['val_accuracy'], label = 'test')\n",
    "  ax2.set_ylabel('Accuracy')\n",
    "  ax2.set_xlabel('Epoch')\n",
    "  ax2.legend(['Train', 'Validation'])\n",
    "\n",
    "  plt.show()\n",
    "\n",
    "plot_history(history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
